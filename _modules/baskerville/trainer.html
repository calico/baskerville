

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>baskerville.trainer &mdash; baskerville 0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=d45e8c67"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            baskerville
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../baskerville.html">baskerville package</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">baskerville</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">baskerville.trainer</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for baskerville.trainer</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2023 Calico LLC</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     https://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># =========================================================================</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pdb</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tempfile</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">baskerville.helpers.gcs_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">is_gcs_path</span><span class="p">,</span> <span class="n">upload_folder_gcs</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">baskerville</span><span class="w"> </span><span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras</span><span class="w"> </span><span class="kn">import</span> <span class="n">mixed_precision</span>


<div class="viewcode-block" id="parse_loss">
<a class="viewcode-back" href="../../baskerville.html#baskerville.trainer.parse_loss">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">parse_loss</span><span class="p">(</span>
    <span class="n">loss_label</span><span class="p">,</span>
    <span class="n">strategy</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">keras_fit</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">spec_weight</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">total_weight</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">weight_range</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">weight_exp</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Parse loss function from label, strategy, and fitting method.</span>

<span class="sd">    Args:</span>
<span class="sd">      loss_label (str): Loss function label.</span>
<span class="sd">      strategy: tf.distribute.Strategy object.</span>
<span class="sd">      keras_fit (bool): Use Keras fit method instead of custom loop.</span>
<span class="sd">      spec_weight (float): Specificity weight for PoissonKL.</span>
<span class="sd">      total_weight (float): Total weight for PoissionMultinomial.</span>

<span class="sd">    Returns:</span>
<span class="sd">      loss_fn: tf.keras.losses.Loss object.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">strategy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">keras_fit</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">loss_label</span> <span class="o">==</span> <span class="s2">&quot;mse&quot;</span><span class="p">:</span>
            <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">MeanSquaredError</span><span class="p">(</span>
                <span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Reduction</span><span class="o">.</span><span class="n">NONE</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">loss_label</span> <span class="o">==</span> <span class="s2">&quot;bce&quot;</span><span class="p">:</span>
            <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">BinaryCrossentropy</span><span class="p">(</span>
                <span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Reduction</span><span class="o">.</span><span class="n">NONE</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">loss_label</span> <span class="o">==</span> <span class="s2">&quot;poisson_mn&quot;</span><span class="p">:</span>
            <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">PoissonMultinomial</span><span class="p">(</span>
                <span class="n">total_weight</span><span class="o">=</span><span class="n">total_weight</span><span class="p">,</span>
                <span class="n">weight_range</span><span class="o">=</span><span class="n">weight_range</span><span class="p">,</span>
                <span class="n">weight_exp</span><span class="o">=</span><span class="n">weight_exp</span><span class="p">,</span>
                <span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Reduction</span><span class="o">.</span><span class="n">NONE</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">loss_label</span> <span class="o">==</span> <span class="s2">&quot;poisson_kl&quot;</span><span class="p">:</span>
            <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">PoissonKL</span><span class="p">(</span>
                <span class="n">spec_weight</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Reduction</span><span class="o">.</span><span class="n">NONE</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">loss_label</span> <span class="o">==</span> <span class="s2">&quot;mse_udot&quot;</span><span class="p">:</span>
            <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">MeanSquaredErrorUDot</span><span class="p">(</span>
                <span class="n">spec_weight</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Reduction</span><span class="o">.</span><span class="n">NONE</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Poisson</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Reduction</span><span class="o">.</span><span class="n">NONE</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">loss_label</span> <span class="o">==</span> <span class="s2">&quot;mse&quot;</span><span class="p">:</span>
            <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">MeanSquaredError</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">loss_label</span> <span class="o">==</span> <span class="s2">&quot;mse_udot&quot;</span><span class="p">:</span>
            <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">MeanSquaredErrorUDot</span><span class="p">(</span><span class="n">spec_weight</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">loss_label</span> <span class="o">==</span> <span class="s2">&quot;bce&quot;</span><span class="p">:</span>
            <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">BinaryCrossentropy</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">loss_label</span> <span class="o">==</span> <span class="s2">&quot;poisson_kl&quot;</span><span class="p">:</span>
            <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">PoissonKL</span><span class="p">(</span><span class="n">spec_weight</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">loss_label</span> <span class="o">==</span> <span class="s2">&quot;poisson_mn&quot;</span><span class="p">:</span>
            <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">PoissonMultinomial</span><span class="p">(</span>
                <span class="n">total_weight</span><span class="o">=</span><span class="n">total_weight</span><span class="p">,</span>
                <span class="n">weight_range</span><span class="o">=</span><span class="n">weight_range</span><span class="p">,</span>
                <span class="n">weight_exp</span><span class="o">=</span><span class="n">weight_exp</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Poisson</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">loss_fn</span></div>



<div class="viewcode-block" id="Trainer">
<a class="viewcode-back" href="../../baskerville.html#baskerville.trainer.Trainer">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Trainer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Model training class.</span>

<span class="sd">    Args:</span>
<span class="sd">      params (dict): Training parameters dictionary.</span>
<span class="sd">      train_data: Dataset object or list of Dataset objects.</span>
<span class="sd">      eval_data: Dataset object or list of Dataset objects.</span>
<span class="sd">      out_dir (str): Output directory name.</span>
<span class="sd">      strategy: tf.distribute.Strategy object.</span>
<span class="sd">      num_gpu (int): Number of GPUs to use. Default: 1.</span>
<span class="sd">      keras_fit (bool): Use Keras fit method instead of custom loop.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
        <span class="n">train_data</span><span class="p">,</span>
        <span class="n">eval_data</span><span class="p">,</span>
        <span class="n">out_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">log_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">strategy</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">num_gpu</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">keras_fit</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">loss_scale</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">list</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_data</span> <span class="o">=</span> <span class="n">eval_data</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_data</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">list</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval_data</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_data</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_dir</span> <span class="o">=</span> <span class="n">out_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span> <span class="o">=</span> <span class="n">log_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span> <span class="o">=</span> <span class="n">strategy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_gpu</span> <span class="o">=</span> <span class="n">num_gpu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compiled</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_scale</span> <span class="o">=</span> <span class="n">loss_scale</span>

        <span class="c1"># if log_dir is in gcs then create a local temp dir</span>
        <span class="k">if</span> <span class="n">is_gcs_path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">):</span>
            <span class="n">folder_name</span> <span class="o">=</span> <span class="s2">&quot;/&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="mi">3</span><span class="p">:])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">mkdtemp</span><span class="p">()</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="n">folder_name</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">gcs_log_dir</span> <span class="o">=</span> <span class="n">log_dir</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">gcs</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">gcs</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># early stopping</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;patience&quot;</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>

        <span class="c1"># compute batches/epoch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_epoch_batches</span> <span class="o">=</span> <span class="p">[</span><span class="n">td</span><span class="o">.</span><span class="n">batches_per_epoch</span><span class="p">()</span> <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_epoch_batches</span> <span class="o">=</span> <span class="p">[</span><span class="n">ed</span><span class="o">.</span><span class="n">batches_per_epoch</span><span class="p">()</span> <span class="k">for</span> <span class="n">ed</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_data</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_epochs_min</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train_epochs_min&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_epochs_max</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train_epochs_max&quot;</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>

        <span class="c1"># dataset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_datasets</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_indexes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_datasets</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dataset_indexes</span> <span class="o">+=</span> <span class="p">[</span><span class="n">di</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_epoch_batches</span><span class="p">[</span><span class="n">di</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_indexes</span><span class="p">)</span>

        <span class="c1"># loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spec_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;spec_weight&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;total_weight&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_range</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;weight_range&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_exp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;weight_exp&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="s2">&quot;poisson&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">parse_loss</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="p">,</span>
            <span class="n">keras_fit</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spec_weight</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">total_weight</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight_range</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight_exp</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">make_optimizer</span><span class="p">(</span><span class="n">loss_scale</span><span class="o">=</span><span class="n">loss_scale</span><span class="p">)</span>

<div class="viewcode-block" id="Trainer.compile">
<a class="viewcode-back" href="../../baskerville.html#baskerville.trainer.Trainer.compile">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compile</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seqnn_model</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">==</span> <span class="s2">&quot;bce&quot;</span><span class="p">:</span>
                <span class="n">model_metrics</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">metrics</span><span class="o">.</span><span class="n">SeqAUC</span><span class="p">(</span><span class="n">curve</span><span class="o">=</span><span class="s2">&quot;ROC&quot;</span><span class="p">),</span>
                    <span class="n">metrics</span><span class="o">.</span><span class="n">SeqAUC</span><span class="p">(</span><span class="n">curve</span><span class="o">=</span><span class="s2">&quot;PR&quot;</span><span class="p">),</span>
                <span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">num_targets</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">output_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">model_metrics</span> <span class="o">=</span> <span class="p">[</span><span class="n">metrics</span><span class="o">.</span><span class="n">PearsonR</span><span class="p">(</span><span class="n">num_targets</span><span class="p">),</span> <span class="n">metrics</span><span class="o">.</span><span class="n">R2</span><span class="p">(</span><span class="n">num_targets</span><span class="p">)]</span>

            <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
                <span class="n">loss</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">model_metrics</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compiled</span> <span class="o">=</span> <span class="kc">True</span></div>


<div class="viewcode-block" id="Trainer.fit_keras">
<a class="viewcode-back" href="../../baskerville.html#baskerville.trainer.Trainer.fit_keras">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit_keras</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seqnn_model</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">seqnn_model</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">==</span> <span class="s2">&quot;bce&quot;</span><span class="p">:</span>
            <span class="n">early_stop</span> <span class="o">=</span> <span class="n">EarlyStoppingMin</span><span class="p">(</span>
                <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">,</span>
                <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;min&quot;</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">patience</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">,</span>
                <span class="n">min_epoch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_epochs_min</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">save_best</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span>
                <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/model_best.h5&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_dir</span><span class="p">,</span>
                <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;min&quot;</span><span class="p">,</span>
                <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">early_stop</span> <span class="o">=</span> <span class="n">EarlyStoppingMin</span><span class="p">(</span>
                <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_pearsonr&quot;</span><span class="p">,</span>
                <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">patience</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">,</span>
                <span class="n">min_epoch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_epochs_min</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">save_best</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span>
                <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/model_best.h5&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_dir</span><span class="p">,</span>
                <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">,</span>
                <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_pearsonr&quot;</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">early_stop</span><span class="p">,</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">TensorBoard</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">,</span> <span class="n">histogram_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/model_check.h5&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_dir</span><span class="p">),</span>
            <span class="n">save_best</span><span class="p">,</span>
        <span class="p">]</span>

        <span class="n">seqnn_model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span>
            <span class="n">epochs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_epochs_max</span><span class="p">,</span>
            <span class="n">steps_per_epoch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_epoch_batches</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
            <span class="n">validation_data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span>
            <span class="n">validation_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_epoch_batches</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Trainer.fit2">
<a class="viewcode-back" href="../../baskerville.html#baskerville.trainer.Trainer.fit2">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit2</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seqnn_model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Train the model using a custom loop for two separate datasets.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">seqnn_model</span><span class="p">)</span>

        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_datasets</span>

        <span class="c1"># inform optimizer about all trainable variables (v2.11-)</span>
        <span class="n">vars_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">trainable_vars</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_datasets</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">di</span><span class="p">]</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">v</span><span class="o">.</span><span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">vars_set</span><span class="p">:</span>
                    <span class="n">vars_set</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
                    <span class="n">trainable_vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">trainable_vars</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">pass</span>

        <span class="c1">################################################################</span>
        <span class="c1"># prep</span>

        <span class="c1"># metrics</span>
        <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_r</span><span class="p">,</span> <span class="n">train_r2</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="n">valid_loss</span><span class="p">,</span> <span class="n">valid_r</span><span class="p">,</span> <span class="n">valid_r2</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_datasets</span><span class="p">):</span>
            <span class="n">num_targets</span> <span class="o">=</span> <span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">di</span><span class="p">]</span><span class="o">.</span><span class="n">output_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">train_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;train</span><span class="si">%d</span><span class="s2">_loss&quot;</span> <span class="o">%</span> <span class="n">di</span><span class="p">))</span>
            <span class="n">train_r</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">PearsonR</span><span class="p">(</span><span class="n">num_targets</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;train</span><span class="si">%d</span><span class="s2">_r&quot;</span> <span class="o">%</span> <span class="n">di</span><span class="p">))</span>
            <span class="n">train_r2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">R2</span><span class="p">(</span><span class="n">num_targets</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;train</span><span class="si">%d</span><span class="s2">_r2&quot;</span> <span class="o">%</span> <span class="n">di</span><span class="p">))</span>
            <span class="n">valid_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;valid</span><span class="si">%d</span><span class="s2">_loss&quot;</span> <span class="o">%</span> <span class="n">di</span><span class="p">))</span>
            <span class="n">valid_r</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">PearsonR</span><span class="p">(</span><span class="n">num_targets</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;valid</span><span class="si">%d</span><span class="s2">_r&quot;</span> <span class="o">%</span> <span class="n">di</span><span class="p">))</span>
            <span class="n">valid_r2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">R2</span><span class="p">(</span><span class="n">num_targets</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;valid</span><span class="si">%d</span><span class="s2">_r2&quot;</span> <span class="o">%</span> <span class="n">di</span><span class="p">))</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># generate decorated train steps</span>
            <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
            <span class="k">def</span><span class="w"> </span><span class="nf">train_step0</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
                <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
                    <span class="n">pred</span> <span class="o">=</span> <span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>
                <span class="n">train_loss</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">loss</span><span class="p">)</span>
                <span class="n">train_r</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                <span class="n">train_r2</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                <span class="n">gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span>
                    <span class="n">loss</span><span class="p">,</span> <span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">trainable_variables</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span>
                    <span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
                <span class="p">)</span>

            <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
            <span class="k">def</span><span class="w"> </span><span class="nf">eval_step0</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>
                <span class="n">valid_loss</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">loss</span><span class="p">)</span>
                <span class="n">valid_r</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                <span class="n">valid_r2</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_datasets</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>

                <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
                <span class="k">def</span><span class="w"> </span><span class="nf">train_step1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
                    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
                        <span class="n">pred</span> <span class="o">=</span> <span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>
                    <span class="n">train_loss</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">loss</span><span class="p">)</span>
                    <span class="n">train_r</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                    <span class="n">train_r2</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                    <span class="n">gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span>
                        <span class="n">loss</span><span class="p">,</span> <span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">trainable_variables</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span>
                        <span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
                    <span class="p">)</span>

                <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
                <span class="k">def</span><span class="w"> </span><span class="nf">eval_step1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
                    <span class="n">pred</span> <span class="o">=</span> <span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>
                    <span class="n">valid_loss</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">loss</span><span class="p">)</span>
                    <span class="n">valid_r</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                    <span class="n">valid_r2</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">train_step0</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
                <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
                    <span class="n">pred</span> <span class="o">=</span> <span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="n">loss_batch_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                    <span class="n">loss_batch</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">loss_batch_len</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">loss_batch</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
                    <span class="n">loss</span> <span class="o">+=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_gpu</span>
                <span class="n">train_r</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                <span class="n">train_r2</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                <span class="n">gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span>
                    <span class="n">loss</span><span class="p">,</span> <span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">trainable_variables</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span>
                    <span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="k">return</span> <span class="n">loss</span>

            <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
            <span class="k">def</span><span class="w"> </span><span class="nf">train_step0_distr</span><span class="p">(</span><span class="n">xd</span><span class="p">,</span> <span class="n">yd</span><span class="p">):</span>
                <span class="n">replica_losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_step0</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">xd</span><span class="p">,</span> <span class="n">yd</span><span class="p">))</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">,</span> <span class="n">replica_losses</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span>
                <span class="p">)</span>
                <span class="n">train_loss</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">loss</span><span class="p">)</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">eval_step0</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>
                <span class="n">valid_loss</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">loss</span><span class="p">)</span>
                <span class="n">valid_r</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                <span class="n">valid_r2</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>

            <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
            <span class="k">def</span><span class="w"> </span><span class="nf">eval_step0_distr</span><span class="p">(</span><span class="n">xd</span><span class="p">,</span> <span class="n">yd</span><span class="p">):</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">eval_step0</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">xd</span><span class="p">,</span> <span class="n">yd</span><span class="p">))</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_datasets</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>

                <span class="k">def</span><span class="w"> </span><span class="nf">train_step1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
                    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
                        <span class="n">pred</span> <span class="o">=</span> <span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                        <span class="n">loss_batch_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                        <span class="n">loss_batch</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">loss_batch_len</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                        <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">loss_batch</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
                        <span class="n">loss</span> <span class="o">+=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_gpu</span>
                    <span class="n">train_loss</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">loss</span><span class="p">)</span>
                    <span class="n">train_r</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                    <span class="n">train_r2</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                    <span class="n">gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span>
                        <span class="n">loss</span><span class="p">,</span> <span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">trainable_variables</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span>
                        <span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="k">return</span> <span class="n">loss</span>

                <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
                <span class="k">def</span><span class="w"> </span><span class="nf">train_step1_distr</span><span class="p">(</span><span class="n">xd</span><span class="p">,</span> <span class="n">yd</span><span class="p">):</span>
                    <span class="n">replica_losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_step1</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">xd</span><span class="p">,</span> <span class="n">yd</span><span class="p">))</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span>
                        <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">,</span> <span class="n">replica_losses</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span>
                    <span class="p">)</span>
                    <span class="n">train_loss</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">loss</span><span class="p">)</span>

                <span class="k">def</span><span class="w"> </span><span class="nf">eval_step1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
                    <span class="n">pred</span> <span class="o">=</span> <span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>
                    <span class="n">valid_loss</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">loss</span><span class="p">)</span>
                    <span class="n">valid_r</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                    <span class="n">valid_r2</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>

                <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
                <span class="k">def</span><span class="w"> </span><span class="nf">eval_step1_distr</span><span class="p">(</span><span class="n">xd</span><span class="p">,</span> <span class="n">yd</span><span class="p">):</span>
                    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">eval_step1</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">xd</span><span class="p">,</span> <span class="n">yd</span><span class="p">))</span>

        <span class="c1"># checkpoint manager</span>
        <span class="n">managers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_datasets</span><span class="p">):</span>
            <span class="n">ckpt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">di</span><span class="p">],</span> <span class="n">optimizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span>
            <span class="p">)</span>
            <span class="n">ckpt_dir</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/model</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_dir</span><span class="p">,</span> <span class="n">di</span><span class="p">)</span>
            <span class="n">manager</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">CheckpointManager</span><span class="p">(</span><span class="n">ckpt</span><span class="p">,</span> <span class="n">ckpt_dir</span><span class="p">,</span> <span class="n">max_to_keep</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">manager</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">:</span>
                <span class="n">ckpt</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">manager</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">)</span>
                <span class="n">ckpt_end</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">+</span> <span class="n">manager</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;ckpt-&quot;</span><span class="p">)</span>
                <span class="n">epoch_start</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">manager</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">[</span><span class="n">ckpt_end</span><span class="p">:])</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">opt_iters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">iterations</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">opt_iters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">iterations</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="s2">&quot;Checkpoint restored at epoch </span><span class="si">%d</span><span class="s2">, optimizer iteration </span><span class="si">%d</span><span class="s2">.&quot;</span>
                    <span class="o">%</span> <span class="p">(</span><span class="n">epoch_start</span><span class="p">,</span> <span class="n">opt_iters</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No checkpoints found.&quot;</span><span class="p">)</span>
                <span class="n">epoch_start</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">managers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">manager</span><span class="p">)</span>

        <span class="c1"># improvement variables</span>
        <span class="n">valid_best</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_datasets</span>
        <span class="n">unimproved</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_datasets</span>

        <span class="c1">################################################################</span>
        <span class="c1"># training loop</span>

        <span class="n">gpu_memory_callback</span> <span class="o">=</span> <span class="n">GPUMemoryUsageCallback</span><span class="p">()</span>
        <span class="n">file_path</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/gpu_mem.txt&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_dir</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
            <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;epoch</span><span class="se">\t</span><span class="s2">batch</span><span class="se">\t</span><span class="s2">gpu_mem(GB)</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">first_step</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="c1"># set up summary writer</span>
        <span class="n">train_log_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span> <span class="o">+</span> <span class="s2">&quot;/train&quot;</span>
        <span class="n">valid_log_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span> <span class="o">+</span> <span class="s2">&quot;/valid&quot;</span>
        <span class="n">train_summary_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">create_file_writer</span><span class="p">(</span><span class="n">train_log_dir</span><span class="p">)</span>
        <span class="n">valid_summary_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">create_file_writer</span><span class="p">(</span><span class="n">valid_log_dir</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">ei</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch_start</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_epochs_max</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">ei</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_epochs_min</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">unimproved</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># shuffle datasets</span>
                <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_indexes</span><span class="p">)</span>

                <span class="c1"># get iterators</span>
                <span class="n">train_data_iters</span> <span class="o">=</span> <span class="p">[</span><span class="nb">iter</span><span class="p">(</span><span class="n">td</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span> <span class="k">for</span> <span class="n">td</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">]</span>

                <span class="c1"># train</span>
                <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                <span class="n">prog_bar</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">Progbar</span><span class="p">(</span>
                    <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_indexes</span><span class="p">)</span>
                <span class="p">)</span>  <span class="c1"># Create Keras Progbar</span>
                <span class="k">for</span> <span class="n">didx</span><span class="p">,</span> <span class="n">di</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_indexes</span><span class="p">):</span>
                    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">safe_next</span><span class="p">(</span><span class="n">train_data_iters</span><span class="p">[</span><span class="n">di</span><span class="p">])</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">di</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="n">train_step0</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">train_step1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">di</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="n">train_step0_distr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">train_step1_distr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">first_step</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Successful first step!&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                        <span class="n">first_step</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="n">prog_bar</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

                    <span class="k">if</span> <span class="p">(</span><span class="n">ei</span> <span class="o">==</span> <span class="n">epoch_start</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">didx</span> <span class="o">&lt;</span> <span class="mi">1000</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">didx</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
                        <span class="n">mem</span> <span class="o">=</span> <span class="n">gpu_memory_callback</span><span class="o">.</span><span class="n">on_batch_end</span><span class="p">()</span>
                        <span class="n">file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">)</span>
                        <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%d</span><span class="se">\t</span><span class="si">%d</span><span class="se">\t</span><span class="si">%.2f</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">ei</span><span class="p">,</span> <span class="n">didx</span><span class="p">,</span> <span class="n">mem</span><span class="p">))</span>

                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">%d</span><span class="s2"> - </span><span class="si">%d</span><span class="s2">s&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">ei</span><span class="p">,</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">)))</span>
                <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_datasets</span><span class="p">):</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  Data </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">di</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
                    <span class="n">model</span> <span class="o">=</span> <span class="n">seqnn_model</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">di</span><span class="p">]</span>
                    <span class="k">with</span> <span class="n">train_summary_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
                        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span>
                            <span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">[</span><span class="n">di</span><span class="p">]</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">step</span><span class="o">=</span><span class="n">ei</span>
                        <span class="p">)</span>
                        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">train_r</span><span class="p">[</span><span class="n">di</span><span class="p">]</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">step</span><span class="o">=</span><span class="n">ei</span><span class="p">)</span>
                        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;r2&quot;</span><span class="p">,</span> <span class="n">train_r2</span><span class="p">[</span><span class="n">di</span><span class="p">]</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">step</span><span class="o">=</span><span class="n">ei</span><span class="p">)</span>
                        <span class="n">train_summary_writer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

                    <span class="c1"># print training accuracy</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="s2">&quot; - train_loss: </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">train_loss</span><span class="p">[</span><span class="n">di</span><span class="p">]</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span>
                    <span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; - train_r: </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">train_r</span><span class="p">[</span><span class="n">di</span><span class="p">]</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; - train_r: </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">train_r2</span><span class="p">[</span><span class="n">di</span><span class="p">]</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

                    <span class="c1"># evaluate</span>
                    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_data</span><span class="p">[</span><span class="n">di</span><span class="p">]</span><span class="o">.</span><span class="n">dataset</span><span class="p">:</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">di</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                                <span class="n">eval_step0</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="n">eval_step1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">di</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                                <span class="n">eval_step0_distr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="n">eval_step1_distr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

                    <span class="k">with</span> <span class="n">valid_summary_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
                        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span>
                            <span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="n">valid_loss</span><span class="p">[</span><span class="n">di</span><span class="p">]</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">step</span><span class="o">=</span><span class="n">ei</span>
                        <span class="p">)</span>
                        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">valid_r</span><span class="p">[</span><span class="n">di</span><span class="p">]</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">step</span><span class="o">=</span><span class="n">ei</span><span class="p">)</span>
                        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;r2&quot;</span><span class="p">,</span> <span class="n">valid_r2</span><span class="p">[</span><span class="n">di</span><span class="p">]</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">step</span><span class="o">=</span><span class="n">ei</span><span class="p">)</span>
                        <span class="n">valid_summary_writer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

                    <span class="c1"># print validation accuracy</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="s2">&quot; - valid_loss: </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">valid_loss</span><span class="p">[</span><span class="n">di</span><span class="p">]</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span>
                    <span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; - valid_r: </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">valid_r</span><span class="p">[</span><span class="n">di</span><span class="p">]</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; - valid_r2: </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">valid_r2</span><span class="p">[</span><span class="n">di</span><span class="p">]</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
                    <span class="n">early_stop_stat</span> <span class="o">=</span> <span class="n">valid_r</span><span class="p">[</span><span class="n">di</span><span class="p">]</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

                    <span class="c1"># upload to gcs</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gcs</span><span class="p">:</span>
                        <span class="n">upload_folder_gcs</span><span class="p">(</span><span class="n">train_log_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gcs_log_dir</span><span class="p">)</span>
                        <span class="n">upload_folder_gcs</span><span class="p">(</span><span class="n">valid_log_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gcs_log_dir</span><span class="p">)</span>
                    <span class="c1"># checkpoint</span>
                    <span class="n">managers</span><span class="p">[</span><span class="n">di</span><span class="p">]</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
                        <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/model</span><span class="si">%d</span><span class="s2">_check.h5&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_dir</span><span class="p">,</span> <span class="n">di</span><span class="p">),</span>
                        <span class="n">include_optimizer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="p">)</span>

                    <span class="c1"># check best</span>
                    <span class="k">if</span> <span class="n">early_stop_stat</span> <span class="o">&gt;</span> <span class="n">valid_best</span><span class="p">[</span><span class="n">di</span><span class="p">]:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; - best!&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
                        <span class="n">unimproved</span><span class="p">[</span><span class="n">di</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                        <span class="n">valid_best</span><span class="p">[</span><span class="n">di</span><span class="p">]</span> <span class="o">=</span> <span class="n">early_stop_stat</span>
                        <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
                            <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/model</span><span class="si">%d</span><span class="s2">_best.h5&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_dir</span><span class="p">,</span> <span class="n">di</span><span class="p">),</span>
                            <span class="n">include_optimizer</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">unimproved</span><span class="p">[</span><span class="n">di</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

                    <span class="c1"># reset metrics</span>
                    <span class="n">train_loss</span><span class="p">[</span><span class="n">di</span><span class="p">]</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>
                    <span class="n">train_r</span><span class="p">[</span><span class="n">di</span><span class="p">]</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>
                    <span class="n">train_r2</span><span class="p">[</span><span class="n">di</span><span class="p">]</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>
                    <span class="n">valid_loss</span><span class="p">[</span><span class="n">di</span><span class="p">]</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>
                    <span class="n">valid_r</span><span class="p">[</span><span class="n">di</span><span class="p">]</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>
                    <span class="n">valid_r2</span><span class="p">[</span><span class="n">di</span><span class="p">]</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span></div>


<div class="viewcode-block" id="Trainer.fit_tape">
<a class="viewcode-back" href="../../baskerville.html#baskerville.trainer.Trainer.fit_tape">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit_tape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seqnn_model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Train the model using a custom tf.GradientTape loop.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">seqnn_model</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">seqnn_model</span><span class="o">.</span><span class="n">model</span>

        <span class="c1"># metrics</span>
        <span class="n">num_targets</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">output_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;train_loss&quot;</span><span class="p">)</span>
        <span class="n">train_r</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">PearsonR</span><span class="p">(</span><span class="n">num_targets</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;train_r&quot;</span><span class="p">)</span>
        <span class="n">train_r2</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">R2</span><span class="p">(</span><span class="n">num_targets</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;train_r2&quot;</span><span class="p">)</span>
        <span class="n">valid_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;valid_loss&quot;</span><span class="p">)</span>
        <span class="n">valid_r</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">PearsonR</span><span class="p">(</span><span class="n">num_targets</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;valid_r&quot;</span><span class="p">)</span>
        <span class="n">valid_r2</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">R2</span><span class="p">(</span><span class="n">num_targets</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;valid_r2&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_scale</span><span class="p">:</span>

                <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
                <span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
                    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
                        <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>
                        <span class="n">scaled_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">get_scaled_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
                    <span class="n">train_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
                    <span class="n">train_r</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                    <span class="n">train_r2</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                    <span class="n">scaled_gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span>
                        <span class="n">scaled_loss</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span>
                    <span class="p">)</span>
                    <span class="n">gradients</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">get_unscaled_gradients</span><span class="p">(</span><span class="n">scaled_gradients</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span>
                        <span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
                    <span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>

                <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
                <span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
                    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
                        <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>
                    <span class="n">train_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
                    <span class="n">train_r</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                    <span class="n">train_r2</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                    <span class="n">gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">agc_clip</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">gradients</span> <span class="o">=</span> <span class="n">adaptive_clip_grad</span><span class="p">(</span>
                            <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">,</span> <span class="n">gradients</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">agc_clip</span>
                        <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span>
                        <span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
                    <span class="p">)</span>

            <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
            <span class="k">def</span><span class="w"> </span><span class="nf">eval_step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>
                <span class="n">valid_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
                <span class="n">valid_r</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                <span class="n">valid_r2</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
                <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
                    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="n">loss_batch_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                    <span class="n">loss_batch</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">loss_batch_len</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">loss_batch</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
                    <span class="n">loss</span> <span class="o">+=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_gpu</span>
                <span class="n">train_r</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                <span class="n">train_r2</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                <span class="n">gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span>
                    <span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="k">return</span> <span class="n">loss</span>

            <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
            <span class="k">def</span><span class="w"> </span><span class="nf">train_step_distr</span><span class="p">(</span><span class="n">xd</span><span class="p">,</span> <span class="n">yd</span><span class="p">):</span>
                <span class="n">replica_losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_step</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">xd</span><span class="p">,</span> <span class="n">yd</span><span class="p">))</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">,</span> <span class="n">replica_losses</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span>
                <span class="p">)</span>
                <span class="n">train_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">eval_step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>
                <span class="n">valid_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
                <span class="n">valid_r</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                <span class="n">valid_r2</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>

            <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
            <span class="k">def</span><span class="w"> </span><span class="nf">eval_step_distr</span><span class="p">(</span><span class="n">xd</span><span class="p">,</span> <span class="n">yd</span><span class="p">):</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">eval_step</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">xd</span><span class="p">,</span> <span class="n">yd</span><span class="p">))</span>

        <span class="c1"># checkpoint manager</span>
        <span class="n">ckpt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">seqnn_model</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span>
        <span class="n">manager</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">CheckpointManager</span><span class="p">(</span><span class="n">ckpt</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_dir</span><span class="p">,</span> <span class="n">max_to_keep</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">manager</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">:</span>
            <span class="n">ckpt</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">manager</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">)</span>
            <span class="n">ckpt_end</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">+</span> <span class="n">manager</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;ckpt-&quot;</span><span class="p">)</span>
            <span class="n">epoch_start</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">manager</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">[</span><span class="n">ckpt_end</span><span class="p">:])</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">opt_iters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">iterations</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">opt_iters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">iterations</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;Checkpoint restored at epoch </span><span class="si">%d</span><span class="s2">, optimizer iteration </span><span class="si">%d</span><span class="s2">.&quot;</span>
                <span class="o">%</span> <span class="p">(</span><span class="n">epoch_start</span><span class="p">,</span> <span class="n">opt_iters</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No checkpoints found.&quot;</span><span class="p">)</span>
            <span class="n">epoch_start</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># improvement variables</span>
        <span class="n">valid_best</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="n">unimproved</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># set up summary writer</span>
        <span class="n">train_log_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span> <span class="o">+</span> <span class="s2">&quot;/train&quot;</span>
        <span class="n">valid_log_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span> <span class="o">+</span> <span class="s2">&quot;/valid&quot;</span>
        <span class="n">train_summary_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">create_file_writer</span><span class="p">(</span><span class="n">train_log_dir</span><span class="p">)</span>
        <span class="n">valid_summary_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">create_file_writer</span><span class="p">(</span><span class="n">valid_log_dir</span><span class="p">)</span>

        <span class="c1"># training loop</span>
        <span class="n">gpu_memory_callback</span> <span class="o">=</span> <span class="n">GPUMemoryUsageCallback</span><span class="p">()</span>
        <span class="n">file_path</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/gpu_mem.txt&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_dir</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
            <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;epoch</span><span class="se">\t</span><span class="s2">batch</span><span class="se">\t</span><span class="s2">gpu_mem(GB)</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">ei</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch_start</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_epochs_max</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">ei</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_epochs_min</span> <span class="ow">and</span> <span class="n">unimproved</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># train</span>
                <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                <span class="n">train_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">si</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_epoch_batches</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">safe_next</span><span class="p">(</span><span class="n">train_iter</span><span class="p">)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">train_step_distr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">train_step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">ei</span> <span class="o">==</span> <span class="n">epoch_start</span> <span class="ow">and</span> <span class="n">si</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Successful first step!&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

                    <span class="c1"># print gpu memory usage</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">ei</span> <span class="o">==</span> <span class="n">epoch_start</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">si</span> <span class="o">&lt;</span> <span class="mi">1000</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">si</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
                        <span class="n">mem</span> <span class="o">=</span> <span class="n">gpu_memory_callback</span><span class="o">.</span><span class="n">on_batch_end</span><span class="p">()</span>
                        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
                            <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%d</span><span class="se">\t</span><span class="si">%d</span><span class="se">\t</span><span class="si">%.2f</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">ei</span><span class="p">,</span> <span class="n">si</span><span class="p">,</span> <span class="n">mem</span><span class="p">))</span>

                <span class="c1"># evaluate</span>
                <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dataset</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">eval_step_distr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">eval_step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

                <span class="c1"># print training accuracy</span>
                <span class="n">train_loss_epoch</span> <span class="o">=</span> <span class="n">train_loss</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="n">train_r_epoch</span> <span class="o">=</span> <span class="n">train_r</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="n">train_r2_epoch</span> <span class="o">=</span> <span class="n">train_r2</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

                <span class="k">with</span> <span class="n">train_summary_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="n">train_loss_epoch</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">ei</span><span class="p">)</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">train_r_epoch</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">ei</span><span class="p">)</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;r2&quot;</span><span class="p">,</span> <span class="n">train_r2_epoch</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">ei</span><span class="p">)</span>
                    <span class="n">train_summary_writer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

                <span class="nb">print</span><span class="p">(</span>
                    <span class="s2">&quot;Epoch </span><span class="si">%d</span><span class="s2"> - </span><span class="si">%d</span><span class="s2">s - train_loss: </span><span class="si">%.4f</span><span class="s2"> - train_r: </span><span class="si">%.4f</span><span class="s2"> - train_r2: </span><span class="si">%.4f</span><span class="s2">&quot;</span>
                    <span class="o">%</span> <span class="p">(</span>
                        <span class="n">ei</span><span class="p">,</span>
                        <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">),</span>
                        <span class="n">train_loss_epoch</span><span class="p">,</span>
                        <span class="n">train_r_epoch</span><span class="p">,</span>
                        <span class="n">train_r2_epoch</span><span class="p">,</span>
                    <span class="p">),</span>
                    <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="c1"># print validation accuracy</span>
                <span class="n">valid_loss_epoch</span> <span class="o">=</span> <span class="n">valid_loss</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="n">valid_r_epoch</span> <span class="o">=</span> <span class="n">valid_r</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="n">valid_r2_epoch</span> <span class="o">=</span> <span class="n">valid_r2</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

                <span class="k">with</span> <span class="n">valid_summary_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="n">valid_loss_epoch</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">ei</span><span class="p">)</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">valid_r_epoch</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">ei</span><span class="p">)</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;r2&quot;</span><span class="p">,</span> <span class="n">valid_r2_epoch</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">ei</span><span class="p">)</span>
                    <span class="n">valid_summary_writer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

                <span class="nb">print</span><span class="p">(</span>
                    <span class="s2">&quot; - valid_loss: </span><span class="si">%.4f</span><span class="s2"> - valid_r: </span><span class="si">%.4f</span><span class="s2"> - valid_r2: </span><span class="si">%.4f</span><span class="s2">&quot;</span>
                    <span class="o">%</span> <span class="p">(</span><span class="n">valid_loss_epoch</span><span class="p">,</span> <span class="n">valid_r_epoch</span><span class="p">,</span> <span class="n">valid_r2_epoch</span><span class="p">),</span>
                    <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="c1"># upload to gcs</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gcs</span><span class="p">:</span>
                    <span class="n">upload_folder_gcs</span><span class="p">(</span><span class="n">train_log_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gcs_log_dir</span><span class="p">)</span>
                    <span class="n">upload_folder_gcs</span><span class="p">(</span><span class="n">valid_log_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gcs_log_dir</span><span class="p">)</span>

                <span class="c1"># checkpoint</span>
                <span class="n">manager</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
                <span class="n">seqnn_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/model_check.h5&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_dir</span><span class="p">)</span>

                <span class="c1"># check best</span>
                <span class="n">valid_best_epoch</span> <span class="o">=</span> <span class="n">valid_r_epoch</span> <span class="o">+</span> <span class="n">valid_r2_epoch</span> <span class="o">/</span> <span class="mi">4</span>
                <span class="k">if</span> <span class="n">valid_best_epoch</span> <span class="o">&gt;</span> <span class="n">valid_best</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; - best!&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
                    <span class="n">unimproved</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="n">valid_best</span> <span class="o">=</span> <span class="n">valid_best_epoch</span>
                    <span class="n">seqnn_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/model_best.h5&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_dir</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">unimproved</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

                <span class="c1"># reset metrics</span>
                <span class="n">train_loss</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>
                <span class="n">train_r</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>
                <span class="n">train_r2</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>
                <span class="n">valid_loss</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>
                <span class="n">valid_r</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>
                <span class="n">valid_r2</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span></div>


<div class="viewcode-block" id="Trainer.make_optimizer">
<a class="viewcode-back" href="../../baskerville.html#baskerville.trainer.Trainer.make_optimizer">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">make_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss_scale</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Make optimizer object from given parameters.&quot;&quot;&quot;</span>
        <span class="n">cyclical1</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">for</span> <span class="n">lrs_param</span> <span class="ow">in</span> <span class="p">[</span>
            <span class="s2">&quot;initial_learning_rate&quot;</span><span class="p">,</span>
            <span class="s2">&quot;maximal_learning_rate&quot;</span><span class="p">,</span>
            <span class="s2">&quot;final_learning_rate&quot;</span><span class="p">,</span>
            <span class="s2">&quot;train_epochs_cycle1&quot;</span><span class="p">,</span>
        <span class="p">]:</span>
            <span class="n">cyclical1</span> <span class="o">=</span> <span class="n">cyclical1</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">lrs_param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cyclical1</span><span class="p">:</span>
            <span class="n">step_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;train_epochs_cycle1&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="nb">sum</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train_epoch_batches</span>
            <span class="p">)</span>
            <span class="n">initial_learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;initial_learning_rate&quot;</span><span class="p">)</span>
            <span class="n">lr_schedule</span> <span class="o">=</span> <span class="n">Cyclical1LearningRate</span><span class="p">(</span>
                <span class="n">initial_learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;initial_learning_rate&quot;</span><span class="p">],</span>
                <span class="n">maximal_learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;maximal_learning_rate&quot;</span><span class="p">],</span>
                <span class="n">final_learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;final_learning_rate&quot;</span><span class="p">],</span>
                <span class="n">step_size</span><span class="o">=</span><span class="n">step_size</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># schedule (currently OFF)</span>
            <span class="n">initial_learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;decay_steps&quot;</span><span class="p">):</span>
                <span class="n">lr_schedule</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">schedules</span><span class="o">.</span><span class="n">ExponentialDecay</span><span class="p">(</span>
                    <span class="n">initial_learning_rate</span><span class="p">,</span>
                    <span class="n">decay_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;decay_steps&quot;</span><span class="p">,</span> <span class="mi">100000</span><span class="p">),</span>
                    <span class="n">decay_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;decay_rate&quot;</span><span class="p">,</span> <span class="mf">0.96</span><span class="p">),</span>
                    <span class="n">staircase</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">lr_schedule</span> <span class="o">=</span> <span class="n">initial_learning_rate</span>

        <span class="k">if</span> <span class="s2">&quot;warmup_steps&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
            <span class="n">lr_schedule</span> <span class="o">=</span> <span class="n">WarmUp</span><span class="p">(</span>
                <span class="n">initial_learning_rate</span><span class="o">=</span><span class="n">initial_learning_rate</span><span class="p">,</span>
                <span class="n">warmup_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;warmup_steps&quot;</span><span class="p">],</span>
                <span class="n">decay_schedule</span><span class="o">=</span><span class="n">lr_schedule</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">global_clipnorm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;global_clipnorm&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;clip_norm&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
            <span class="n">clip_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;clip_norm&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="s2">&quot;clipnorm&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
            <span class="n">clip_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;clipnorm&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">clip_norm</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># adaptive gradient clipping handled in fit method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">agc_clip</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;agc_clip&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="c1"># optimizer</span>
        <span class="n">optimizer_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;optimizer&quot;</span><span class="p">,</span> <span class="s2">&quot;sgd&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">optimizer_type</span> <span class="o">==</span> <span class="s2">&quot;adam&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">loss_scale</span><span class="p">:</span>
                <span class="n">epsilon_value</span> <span class="o">=</span> <span class="mf">1e-04</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">epsilon_value</span> <span class="o">=</span> <span class="mf">1e-07</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
                <span class="n">learning_rate</span><span class="o">=</span><span class="n">lr_schedule</span><span class="p">,</span>
                <span class="n">beta_1</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;adam_beta1&quot;</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">),</span>
                <span class="n">beta_2</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;adam_beta2&quot;</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">),</span>
                <span class="n">clipnorm</span><span class="o">=</span><span class="n">clip_norm</span><span class="p">,</span>
                <span class="n">global_clipnorm</span><span class="o">=</span><span class="n">global_clipnorm</span><span class="p">,</span>
                <span class="n">epsilon</span><span class="o">=</span><span class="n">epsilon_value</span><span class="p">,</span>
                <span class="n">amsgrad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>  <span class="c1"># reduces performance in my experience</span>

        <span class="k">elif</span> <span class="n">optimizer_type</span> <span class="o">==</span> <span class="s2">&quot;adamw&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span>
                <span class="n">weight_decay</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;weight_decay&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
                <span class="n">learning_rate</span><span class="o">=</span><span class="n">lr_schedule</span><span class="p">,</span>
                <span class="n">beta_1</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;adam_beta1&quot;</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">),</span>
                <span class="n">beta_2</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;adam_beta2&quot;</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">),</span>
                <span class="n">clipnorm</span><span class="o">=</span><span class="n">clip_norm</span><span class="p">,</span>
                <span class="n">global_clipnorm</span><span class="o">=</span><span class="n">global_clipnorm</span><span class="p">,</span>
                <span class="n">amsgrad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>  <span class="c1"># reduces performance in my experience</span>

        <span class="k">elif</span> <span class="n">optimizer_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;sgd&quot;</span><span class="p">,</span> <span class="s2">&quot;momentum&quot;</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span>
                <span class="n">learning_rate</span><span class="o">=</span><span class="n">lr_schedule</span><span class="p">,</span>
                <span class="n">momentum</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;momentum&quot;</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">),</span>
                <span class="n">clipnorm</span><span class="o">=</span><span class="n">clip_norm</span><span class="p">,</span>
                <span class="n">global_clipnorm</span><span class="o">=</span><span class="n">global_clipnorm</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cannot recognize optimization algorithm </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">optimizer_type</span><span class="p">)</span>
            <span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">loss_scale</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">mixed_precision</span><span class="o">.</span><span class="n">LossScaleOptimizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span></div>
</div>



<span class="c1">################################################################</span>
<span class="c1"># AGC</span>
<span class="c1"># https://github.com/sayakpaul/Adaptive-Gradient-Clipping</span>


<div class="viewcode-block" id="compute_norm">
<a class="viewcode-back" href="../../baskerville.html#baskerville.trainer.compute_norm">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute L2 norm of a tensor across an axis.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="n">keepdims</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span></div>



<div class="viewcode-block" id="unitwise_norm">
<a class="viewcode-back" href="../../baskerville.html#baskerville.trainer.unitwise_norm">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">unitwise_norm</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute L2 norm of a tensor across its last dimension.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Scalars and vectors</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">keepdims</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]:</span>  <span class="c1"># Linear layers of shape IO or multihead linear</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">keepdims</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>  <span class="c1"># Conv kernels of shape HWIO</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="p">[</span>
            <span class="mi">0</span><span class="p">,</span>
            <span class="mi">1</span><span class="p">,</span>
            <span class="mi">2</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="n">keepdims</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Got a parameter with shape not in [1, 2, 4]! </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">compute_norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">)</span></div>



<div class="viewcode-block" id="adaptive_clip_grad">
<a class="viewcode-back" href="../../baskerville.html#baskerville.trainer.adaptive_clip_grad">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">adaptive_clip_grad</span><span class="p">(</span>
    <span class="n">parameters</span><span class="p">,</span> <span class="n">gradients</span><span class="p">,</span> <span class="n">clip_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Adaptive gradient clipping.&quot;&quot;&quot;</span>
    <span class="n">new_grads</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">params</span><span class="p">,</span> <span class="n">grads</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">gradients</span><span class="p">):</span>
        <span class="n">p_norm</span> <span class="o">=</span> <span class="n">unitwise_norm</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
        <span class="n">max_norm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">p_norm</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span> <span class="o">*</span> <span class="n">clip_factor</span>
        <span class="n">grad_norm</span> <span class="o">=</span> <span class="n">unitwise_norm</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>
        <span class="n">clipped_grad</span> <span class="o">=</span> <span class="n">grads</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_norm</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">grad_norm</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">))</span>
        <span class="n">new_grad</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">grad_norm</span> <span class="o">&lt;</span> <span class="n">max_norm</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">clipped_grad</span><span class="p">)</span>
        <span class="n">new_grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_grad</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_grads</span></div>



<div class="viewcode-block" id="EarlyStoppingMin">
<a class="viewcode-back" href="../../baskerville.html#baskerville.trainer.EarlyStoppingMin">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">EarlyStoppingMin</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Stop training when a monitored quantity has stopped improving.</span>

<span class="sd">    Args:</span>
<span class="sd">      min_epoch: Minimum number of epochs before considering stopping.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">min_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">EarlyStoppingMin</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_epoch</span> <span class="o">=</span> <span class="n">min_epoch</span>

<div class="viewcode-block" id="EarlyStoppingMin.on_epoch_end">
<a class="viewcode-back" href="../../baskerville.html#baskerville.trainer.EarlyStoppingMin.on_epoch_end">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">current</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_monitor_value</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">current</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span><span class="p">(</span><span class="n">current</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">current</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">restore_best_weights</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">best_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_epoch</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">stopped_epoch</span> <span class="o">=</span> <span class="n">epoch</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">restore_best_weights</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Restoring model weights from the end of the best epoch.&quot;</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">best_weights</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="Cyclical1LearningRate">
<a class="viewcode-back" href="../../baskerville.html#baskerville.trainer.Cyclical1LearningRate">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Cyclical1LearningRate</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">schedules</span><span class="o">.</span><span class="n">LearningRateSchedule</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A LearningRateSchedule that uses cyclical schedule.</span>
<span class="sd">    https://yashuseth.blog/2018/11/26/hyper-parameter-tuning-best-practices-learning-rate-batch-size-momentum-weight-decay/</span>

<span class="sd">    Args:</span>
<span class="sd">      initial_learning_rate (float): The initial learning rate.</span>
<span class="sd">      maximal_learning_rate (float): The maximal learning rate after warm up.</span>
<span class="sd">      final_learning_rate (float): The final learning rate after cycle.</span>
<span class="sd">      step_size (int): Cycle step size.</span>
<span class="sd">      name (str, optional): The name of the schedule. Defaults to &quot;Cyclical1LearningRate&quot;.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">initial_learning_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">maximal_learning_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">final_learning_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">step_size</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Cyclical1LearningRate&quot;</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initial_learning_rate</span> <span class="o">=</span> <span class="n">initial_learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maximal_learning_rate</span> <span class="o">=</span> <span class="n">maximal_learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_learning_rate</span> <span class="o">=</span> <span class="n">final_learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">step_size</span> <span class="o">=</span> <span class="n">step_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="ow">or</span> <span class="s2">&quot;Cyclical1LearningRate&quot;</span><span class="p">):</span>
            <span class="n">initial_learning_rate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">initial_learning_rate</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;initial_learning_rate&quot;</span>
            <span class="p">)</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">initial_learning_rate</span><span class="o">.</span><span class="n">dtype</span>
            <span class="n">maximal_learning_rate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">maximal_learning_rate</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
            <span class="n">final_learning_rate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">final_learning_rate</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>

            <span class="n">step_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">step_size</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
            <span class="n">cycle</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">step</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">step_size</span><span class="p">))</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">step</span> <span class="o">/</span> <span class="n">step_size</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">cycle</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

            <span class="n">lr</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                <span class="n">step</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">step_size</span><span class="p">,</span>
                <span class="n">final_learning_rate</span><span class="p">,</span>
                <span class="n">initial_learning_rate</span>
                <span class="o">+</span> <span class="p">(</span><span class="n">maximal_learning_rate</span> <span class="o">-</span> <span class="n">initial_learning_rate</span><span class="p">)</span>
                <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)),</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">lr</span>

<div class="viewcode-block" id="Cyclical1LearningRate.get_config">
<a class="viewcode-back" href="../../baskerville.html#baskerville.trainer.Cyclical1LearningRate.get_config">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;initial_learning_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_learning_rate</span><span class="p">,</span>
            <span class="s2">&quot;maximal_learning_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">maximal_learning_rate</span><span class="p">,</span>
            <span class="s2">&quot;final_learning_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_learning_rate</span><span class="p">,</span>
            <span class="s2">&quot;step_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_size</span><span class="p">,</span>
        <span class="p">}</span></div>
</div>



<div class="viewcode-block" id="WarmUp">
<a class="viewcode-back" href="../../baskerville.html#baskerville.trainer.WarmUp">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">WarmUp</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">schedules</span><span class="o">.</span><span class="n">LearningRateSchedule</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies a warmup schedule on a given learning rate decay schedule.</span>
<span class="sd">    (h/t HuggingFace.)</span>

<span class="sd">    Args:</span>
<span class="sd">      initial_learning_rate (:obj:`float`): Initial learning rate after the warmup</span>
<span class="sd">        (so this will be the learning rate at the end of the warmup).</span>
<span class="sd">      decay_schedule (:obj:`Callable`): The learning rate or schedule function to</span>
<span class="sd">        apply after the warmup for the rest of training.</span>
<span class="sd">      warmup_steps (:obj:`int`): The number of steps for the warmup part of training.</span>
<span class="sd">      power (:obj:`float`, `optional`): Power to use for the polynomial warmup</span>
<span class="sd">        (defaults is a linear warmup).</span>
<span class="sd">      name (:obj:`str`, `optional`): Optional name prefix for the returned tensors</span>
<span class="sd">        during the schedule.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">initial_learning_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">warmup_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">decay_schedule</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">power</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initial_learning_rate</span> <span class="o">=</span> <span class="n">initial_learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="o">=</span> <span class="n">warmup_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">power</span> <span class="o">=</span> <span class="n">power</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decay_schedule</span> <span class="o">=</span> <span class="n">decay_schedule</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="ow">or</span> <span class="s2">&quot;WarmUp&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">name</span><span class="p">:</span>
            <span class="c1"># Implements polynomial warmup. i.e., if global_step &lt; warmup_steps, the</span>
            <span class="c1"># learning rate will be `global_step/num_warmup_steps * init_lr`.</span>
            <span class="n">global_step_float</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">warmup_steps_float</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">warmup_percent_done</span> <span class="o">=</span> <span class="n">global_step_float</span> <span class="o">/</span> <span class="n">warmup_steps_float</span>
            <span class="n">warmup_learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_learning_rate</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span>
                <span class="n">warmup_percent_done</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">power</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decay_schedule</span><span class="p">):</span>
                <span class="n">warmed_learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decay_schedule</span><span class="p">(</span><span class="n">step</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">warmed_learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decay_schedule</span>
            <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span>
                <span class="n">global_step_float</span> <span class="o">&lt;</span> <span class="n">warmup_steps_float</span><span class="p">,</span>
                <span class="k">lambda</span><span class="p">:</span> <span class="n">warmup_learning_rate</span><span class="p">,</span>
                <span class="k">lambda</span><span class="p">:</span> <span class="n">warmed_learning_rate</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="p">)</span>

<div class="viewcode-block" id="WarmUp.get_config">
<a class="viewcode-back" href="../../baskerville.html#baskerville.trainer.WarmUp.get_config">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;initial_learning_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_learning_rate</span><span class="p">,</span>
            <span class="s2">&quot;decay_schedule&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">decay_schedule</span><span class="p">,</span>
            <span class="s2">&quot;warmup_steps&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span><span class="p">,</span>
            <span class="s2">&quot;power&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">power</span><span class="p">,</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
        <span class="p">}</span></div>
</div>



<div class="viewcode-block" id="safe_next">
<a class="viewcode-back" href="../../baskerville.html#baskerville.trainer.safe_next">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">safe_next</span><span class="p">(</span><span class="n">data_iter</span><span class="p">,</span> <span class="n">retry</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">sleep</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">attempts</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">d</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">while</span> <span class="n">d</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">attempts</span> <span class="o">&lt;</span> <span class="n">retry</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">d</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">data_iter</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">tf</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">AbortedError</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;AbortedError, which has previously indicated NFS daemon restart.&quot;</span><span class="p">,</span>
                <span class="n">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">sleep</span><span class="p">)</span>
        <span class="n">attempts</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># let it crash</span>
        <span class="n">d</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">data_iter</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">d</span></div>



<div class="viewcode-block" id="CheckGradientNA">
<a class="viewcode-back" href="../../baskerville.html#baskerville.trainer.CheckGradientNA">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">CheckGradientNA</span><span class="p">(</span><span class="n">gradients</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">grad</span> <span class="ow">in</span> <span class="n">gradients</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_any</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">is_nan</span><span class="p">(</span><span class="n">grad</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;NaN gradient detected.&quot;</span><span class="p">)</span></div>



<span class="c1"># Define a custom callback class to track GPU memory usage</span>
<div class="viewcode-block" id="GPUMemoryUsageCallback">
<a class="viewcode-back" href="../../baskerville.html#baskerville.trainer.GPUMemoryUsageCallback">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">GPUMemoryUsageCallback</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">):</span>
<div class="viewcode-block" id="GPUMemoryUsageCallback.on_train_begin">
<a class="viewcode-back" href="../../baskerville.html#baskerville.trainer.GPUMemoryUsageCallback.on_train_begin">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Enable memory growth to avoid GPU memory allocation issues</span>
        <span class="n">physical_devices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s2">&quot;GPU&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">physical_devices</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">device</span> <span class="ow">in</span> <span class="n">physical_devices</span><span class="p">:</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">set_memory_growth</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span></div>


<div class="viewcode-block" id="GPUMemoryUsageCallback.on_batch_end">
<a class="viewcode-back" href="../../baskerville.html#baskerville.trainer.GPUMemoryUsageCallback.on_batch_end">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">gpu_memory</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">get_memory_info</span><span class="p">(</span><span class="s2">&quot;GPU:0&quot;</span><span class="p">)</span>
        <span class="n">current_memory</span> <span class="o">=</span> <span class="n">gpu_memory</span><span class="p">[</span><span class="s2">&quot;peak&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="mf">1e9</span>  <span class="c1"># Convert to GB</span>
        <span class="k">return</span> <span class="n">current_memory</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, David Kelly.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>